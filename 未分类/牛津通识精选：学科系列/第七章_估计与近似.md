# 第七章_估计与近似

第七章估计与近似

第七章

估计与近似

大多数人认为数学是一门纯净、精确的学科。我们经过在中小学的学习，料想数学问题如果可以被简洁地陈述，大概就能得到简练地回答，通常是一个简单的公式。而继续学习大学阶段数学的人，尤其是那些专门研究数学的人，很快就发现这样的想法实在是大错特错。对于很多问题来说，如果有人能够找到解答的精确公式，那简直完全出人意料，如同奇迹一般。多数情况下，我们不得不满足于大致的估计。在你对此感到习以为常之前，这些估计总是看似很丑陋，难以令人满意。然而，品尝一下其中的滋味也是值得的，否则你就会错过数学中很多最伟大的定理以及最有趣的未解决问题。

无法用简单公式表达的简单序列

记a

1

，a

2

，a

3

，…为一列实数，根据如下规则产生。第一个数a

1

等于1，后面各个数都是前一个数加上其平方根。也就是，对任意n，我们让

。基于这个简单的规则，显然可以提出问题：a

n

是什么数？

为了对这个问题有些感性认识，让我们对较小的几个n来算出a

n

。我们有

。接下来：等等等等。注意，等号右端的表达式看起来无法简化，而且每个新的表达式都是前一个长度的两倍。从这个观察中，很容易得出，数字a

1

2

的表达式中将会出现1024个2，它们中的大多数都深深地位于根号丛中。这样的表达式并不会使我们对数字a

1

2

有多深的了解。

那么我们因此就应当放弃去理解这个序列吗？不。尽管当n比较大时，要考虑a

n

的精确值似乎没有好办法，但这并未排除得到较准确估计的可能性。实际上，一个好的估计最终可能反而会更有用处。我上面写出了a

5

的精确表达式，但和a

5

约为

这条信息比起来，这个表达式让你更好地理解a

5

了吗？

所以，让我们不要再问a

n

是什么，转而去问a

n

大约是多大。也就是，让我们寻找能给出a

n

较优近似值的简单公式。这样的公式是存在的：a

n

大约为n

2

/4。要严格地证明需要一点技巧，但要看出为什么这个估计是合理的，我们要注意：

也就是说，如果b

n

=n

2

/4，那么

。要是没有其中的“+1/4”的话，这个式子就会告诉我们b

n

正和a

n

的生成方法一样。而当n较大时，加上1/4“只不过是个小扰动”（这就是我略去证明的部分），所以b

n

可以看作近似正确地生成，由此推出b

n

即n

2

/4给出了a

n

较好的近似，正如我之前所断言的。

近似的方法

作类似于刚才的关于近似的论断时，明确什么才算是较好的近似很重要，因为标准会随着情景的不同而变化。如果想用一条能够简单定义的序列b

1

，b

2

，b

3

，…来近似一条稳定增大的序列a

1

，a

2

，a

3

，…，那我们所能期待的最优近似——实则很少能够达到，就是每一对a

n

和b

n

的差距都小于一定值——诸如1000。那么随着a

n

和b

n

增大，它们的

比值

会非常接近于1。例如，假设某时有a

n

=2408597348632498758828，以及b

n

=2408597348632498759734。那么b

n

-a

n

=906，这个差虽然是个大数，但与a

n

和b

n

比起来就微不足道了。如果b

n

是在这种意义上对a

n

的近似，我们可以说a

n

和b

n

是“相差常数以内的相等”。

另一类较优的近似是，随着n的增大，a

n

和b

n

的比值变得非常接近1。当a

n

和b

n

相差常数以内相等时，这种情况是成立的，但它在其他一些情况下也会成立。例如，如果a

n

=n

2

而b

n

=n

2

+3n，则比值b

n

a

n

为1+3n，在n较大时很接近1，尽管a

n

和b

n

的

差

3n会很大。

即便这种情况常常也是难以企及的，如果能找到更弱的近似方法我们就会很高兴了。常见的一种方法是，如果a

n

和b

n

“相差常数

倍

以内相等”，就视之为近似相等。它的意思是，a

n

/b

n

和b

n

/a

n

都不会超过某个固定的数——诸如1000也是可能的，但越小越好。换言之，此时不是a

n

和b

n

的差，而是它们的比值保持在某个限度内。

要说两个相差1000倍的数大致相同，这或许看似很不合情理。但这是因为我们总习惯于处理较小的数。自然没有人会将17和13 895看作大致相同，但宽泛地讲，要说下面这样两个数规模

相类

则并不显得很荒唐：

2904756294089761562389545345987608890796872347514348757775468和

3609823459872097612349870982498634087623457796784587345987166464

尽管第二个数比第一个数大1000倍以上，但它们的数位大体相同——都在60到65位之间。既然没有其他有趣的性质，这一点很可能就是我们所关注的全部。

如果连

这样

程度的近似都是奢求，那也常常值得去找出两条参考序列b

1

，b

2

，b

3

，…和c

1

，c

2

，c

3

，

…，并证明b

n

总小于a

n

，而c

n

总大于a

n

。那么我们可以说b

n

是a

n

的“下界”，c

n

是a

n

的“上界”。比如，一位数学家想估计某个量a

n

，他可能会说：“我不知道a

n

的值是多少，甚至连近似值也找不到，但我能够证明它至少是n

3

/2，但不大于n

3

。”如果这个问题相当困难，那这样的一个定理就可能成为重大进展。

关于对数、平方根等你只需要知道这些

估计和近似遍布于数学之中，而这个领域以外的人却不太了解这一点，部分原因在于，为了谈论近似，要使用类似于“大约和logn的速度一样快”，或者“限制在相差一个常数内为根号t”这样的语言，而这对多数人来说意义不大。幸而，对于较大数的对数或平方根，如果有人只关心

近似

值，便很容易理解，这一类语言也不难懂。

如果你取两个大的正整数m和n，想快速得出乘积mn的估值，那你应该怎么做？较好的办法是，一开始先数一下m和n各自的位数，如果m有h位，n有k位，那么m位于10

h

-

1

和10

h

之间，n位于10

k

-

1

和10

k

之间，所以mn位于10

h

+

k

-

2

和10

h

+

k

之间。于是，仅仅数一数m和n的位数就可以“在100倍以内”决定mn，即mn必落在10

h

+

k

-

2

和10

h

+

k

这两个数之间，且10

h

+

k

仅比10

h

+

k

-

2

大100倍。如果你折中一下，取10

h

+

k

-

1

作为估计值，那么它与mn相差的因子至多为10。

换句话说，如果你只在“相差常数倍以内”的程度上关心某个数，那么乘法立刻就变简单了：取m和n两个数，数数它们合起来的位数，减去1（如果你在乎这一点），写下一个有这么多位的数。例如，1 293 875（7位）乘以20 986 759 777（11位）大致接近10 000 000 000 000 000（17位）。如果你想做得更仔细一点，那么可以用上第一个数的首位1及第二个数的首位2，也就意味着20 000 000 000 000 000是个更优的估计值，不过在很多场合下这样的精度是不必要的。

既然近似乘法这么简单，近似平方也就很简单了——只要把原来的数替换为一个两倍位数的新数。由此得出，把n的位数

减半

可以求出n平方根的近似值。类似地，将位数除以3可以求出立方根的近似值。更一般地，如果n是个大整数，t是任一正数，那么n

t

的位数大约为n的位数乘以t。

关于对数呢？从近似的观点看它们其实极为简单：一个数的对数基本上就是它所包含的位数。例如，34587和492 348 797 548 735的对数分别约为5和15。

实际上，数一个数的位数所近似的是它以10为底的对数，即在便携计算器上按LOG键得到的数。通常，数学家谈论对数指的都是所谓的“自然”对数，也就是以e为底的对数。尽管e这个数的确很自然也很重要，但我们在此只要了解：一个数的自然对数，即在计算器上按LN键得到的数，大体上是它的位数乘以2.3上下。于是2 305 799 985 748的自然对数约为：13×2.3=29.9。（如果你了解对数，你会知道真正应当乘上的数是log

e

10。）

这一过程也可以反过来进行。假设你有一个数t且知道它是另一个数n的自然对数。那么数n称作t的

指数幂

，记作e

t

。那么n大致是多少呢？刚才为了得到t，我们数n的位数并乘以2.3。所以n的位数必定约为t/2.3。这就决定了n的大小，至少是近似值。

我上面给出的近似值定义最主要的用途是作比较。例如，现在我们能够明显看出，对大数n而言，其对数要远小于立方根：比如，如果n有75位，它的立方根将会很大——大约有25位数，但它的自然对数则大约仅为75×2.3=172.5。类似地，数m的指数幂会远大于它的乘方，如m

1

0

。例如，若m有50位，那么m

1

0

大约有500位，但e

m

大约有m 2.3位，远大于500。

对数字n=941 192施行不同的运算，得到的近似结果如下表所示。我没有包含进e

n

，因为如果要这么做，那我就得给这本书换个名字了。

素数定理

素数是大于1且不能被其他整数——1和自身显然除外——整除的整数。小于150的所有素数有2， 3， 5， 7， 11， 13， 17， 19， 23， 29， 31， 37， 41， 43， 47， 53， 59， 61， 67， 71， 73， 79， 83， 89， 97， 101， 103， 107， 109， 113， 127， 131， 137， 139和149。小于150的其他数都可以做因子分解：例如91=7×13。（你可能会担心，将1排除在素数的定义之外似乎不合情理。这并不表达数的某种深层事实，只是碰巧成为一个有用的惯例，采纳这样的定义能使任意数被分解为素数的方式仅有一种。）

自从古希腊时期以来，素数就一直困扰着数学家们，因为它们表面上多多少少是随机分布的，但又并非全然随机。从没有人找出一种简单的规则，能够告诉我们第n个素数是多少（当然可以下番工夫列出前n个素数，但这算不上是简单的规则，而且当n很大时会很不切实际），几乎也不太可能会有这么一种规则。但另一方面，仅仅检查前35个素数，也能向我们透露一些有意思的特征。如果你算出相邻两个素数的差，那么你会得到下面这个新的序列：1， 2， 2， 4， 2， 4， 2， 4， 6， 2， 6， 4， 2， 4， 6， 6， 2， 6， 4， 2， 6， 4， 6， 8， 4， 2， 4， 2， 4， 14， 4， 6， 2， 10。（即1=3-2， 2=5-3， 2=7-5， 4=11-7等等。）这列数仍显得有些不规则，但这些数有一个趋势，大致可以看出它们逐渐在增大。显然它们不是稳定地增大的，但最开始的几个数都不大于4，而10和14这样的数直到后来才会出现。

如果你写出前1000个素数，那么相邻素数间距增大的趋势就会变得更加明显。也就是说，和小素数比起来，大素数的出现越来越稀疏。我们正可以预料到这一点，因为大数不成为素数的方式更多了。例如，可能会有人猜测10 001是素数，尤其因为它无法被2，3，5，7，11，13，17以及19整除——但实际上它等于73×137。

有自尊心的数学家绝不会满足于仅仅观察到（甚至没有得到严格地证明）大素数比小素数稀少。他一定想要知道，它们稀少到

何种具体程度

。如果你在1 000 001和1 010 000之间随机取一数，那么这个数有多大的机会是素数？换言之，1 000 000附近的素数“密度”是多大？它是极其小还是仅仅比较小？

没有接触过大学数学的人很少会提出这样的问题，其原因在于，他们没掌握将问题公式化表达并进一步思考所需的语言。不过，若是这章到现在为止你都看懂了，那么你就能够欣赏到数学中最伟大的成就之一：素数定理。定理陈述的是，在数n附近的素数密度约为1/log

e

n，即1除以n的自然对数。

现在再来考虑1 000 001和1 010 000之间取随机数为素数的机会大小。这个区间内的数都大体等于100万。按照素数定理，密度因而约为1除以100万的自然对数。它以10为底的对数是6（在这个例子中，数位数会得到7，但既然我们知道精确答案，不妨使用精确值），所以自然对数约为6×2.3，即13.8。因此，1 000 001和1 010 000之间平均每14个数中有1个是素数，即略多于7 。相比之下，小于100的素数共有24个，即几乎占所有数的四分之一，这就说明了随着数的增大，素数密度是如何减小的。

既然素数分布有零零散散、颇似随机的性质，而我们却能证明其如此多的特点，这足以令人十分惊讶。有意思的是，关于素数的定理通常都是通过

利用

这种看似随机的性质得到证明的。例如，维诺格拉多夫在1937年证明的一个著名定理认为，任意充分大的奇数都可以分解为三个素数之和。我无法在本书中解释他是怎样证明的，但他绝对没有找出将奇数表达为三素数之和的

方法

。这样的思路几乎注定会失败，因为即使是生成这些素数本身也非常困难。基于哈代和利特伍德之前的工作，他大体按照下述办法来论证。如果你能够按照和素数分布同样的密度来真正随机地选取一些数，那么概率论的某种初步理论就能够表明，你几乎一定能够将所有充分大的数表示为你所取的这些数中的三个之和。实际上，你能够以多种不同方式进行这一分解。因为素数是类似于随机的（证明中较难的部分就是要说明，“类似于随机”是什么意思，再加以严格证明），它们的行为就相仿于随机选取的序列，所以所有充分大的数都是三素数之和——同样也以多种方式。为了解释这种现象，这里我们以35为例，列出它分解为三素数之和的所有方式：

35=2+2+31=3+3+29=3+13+19=5+7+23

=5+11+19=5+13+17=7+11+17=11+11+13

关于素数的很多研究都具有此类特点。你首先对素数设计一种概率模型，即假装告诉自己，它们是根据某种随机过程挑选出来的。接下来，在假设素数的确是随机产生的情况下，求证有哪些论断是正确的。这样可以使你猜测出很多问题的答案。最后，你努力表明，这个模型足够现实，能够保证你的猜测近似准确。要注意的是，如果强迫在论证中的每一步都给出精确答案，那这个思路就是不可能的。

很有意思，概率模型不仅仅是物理现象的模型，还能成为另一数学分支的模型。尽管素数的真实分布是严格确定下来的，可某种程度上它们看起来也像是实验数据。一旦这样看待它们，我们就很想去设计对应的简化模型，来预测特定概率论问题的答案是什么样的。这种模型有时的确曾使人们得到对素数本身的有效证明。

这种风格的论证取得了某些显著的成功，但它依然没能解决许多著名问题。例如，哥德巴赫猜想断言，任意大于4的偶数都可以表示为两个奇素数之和。这个猜想看起来比维诺格拉多夫所解答的三素数猜想要难得多。此外还有孪生素数猜想

[1]

，它声称有无穷对相距为2的素数，诸如17与19，137与139。表达这个问题的另一种方式是，如果你写出相邻素数之差，就像我之前做过的那样，那么2永远都会出现（尽管越来越稀少）。

数学中最著名的未决问题大概要数黎曼假设了。这个假设有若干种等价的表达形式，其中一种涉及素数定理给出的估计的精度。我之前说过，素数定理告诉我们在某数附近素数的近似密度。根据这个信息，我们可以计算出，不大于n的素数大约有多少。但这个“大约”有多“大约”？如果p（n）是不大于n的素数个数的真实值，q（n）是根据素数定理得到的估计值，那么黎曼猜想断言，p（n）和q（n）的差不会比

大太多。如果能够证明这样的精度确实成立，那么它将会有很多的应用，但迄今所得到的结果比这要弱得多。

排序算法

数学另有一个分支领域，理论计算机科学，其中满是

粗略的

估计。如果有人要写一个计算机程序完成特定任务，那么程序当然运行得越快越好。理论计算机科学家提出了这样的问题：我们所能期望的最快速度是多快？

要精确地回答这个问题几乎总是不现实的，所以我们转而证明诸如“当输入规模为n时，这种算法的运行步数约为n

2

”这样的论断。由此出发我们可以总结出，一台普通的个人电脑有可能处理的输入规模（简言之，即你想要分析的信息量）为1000，而不是1 000 000。于是，这样的估计就有了实际的重要性。

计算机能够完成的一项非常有用的任务被称为排序，即将为数很多的对象按照给定标准排列顺序。举例来说，想象一下你想要根据喜好程度来排列一系列对象（不一定非要是无生命的，也有可能是一项工作的应聘者之类）。设想，你无法对每个对象赋予一数值来表示有多喜欢它，但是若给定任意两个对象，你总能确定更喜欢哪一个。再设想，你的偏好是前后一致的，意思是指，永远不可能出现这样的情况：喜欢A胜于B，喜欢B胜于C，又喜欢C胜于A。如果你不想为这个任务花太多时间，那么将比较次数最小化就会很有意义。

当对象很少时，很容易看出要怎样做。比如有两个对象，那你至少要作一次比较，一旦比较了你也就知道了它们的排列顺序。若有三个对象A、B、C，那么一次比较是不够的，但总得从某个比较开始，从哪个开始都无妨。为了论证，假设你先比较了A和B，更喜欢A。这时你必须用A和B中的一个和C进行比较。如果你用A和C来比较，并且更喜欢C，那么你就知道了你的偏好顺序是C，A，B.但如果你发现更喜欢A，那么关于B和C，你就只知道它们都没有A讨你喜欢。所以这时需要进行第三次比较，以便能将B和C加入排序。综上所述，三次比较总是充分的，而且有时也是必要的。

有四个对象A、B、C、D时情况如何呢？分析起来就更加困难了。你可能仍从比较A和B开始。但一旦比完这一对，接下来的比较就会有两种本质不同的可能性。一种是用A或B来比较C，另一种是比较C和D，哪种主意更好并不明显。

设想你要比较B和C。如果幸运，你就能够对A、B、C进行排序。假设排序就是A，B，C。接下来还需要考虑D适合什么位置。最好的办法是先比D和B。在这之后，你就只需再比较一次，即比较D和A（如果D比B好）或比较D和C（如果B比D好）。以上一共比较了四次——两次来确定A、B、C的顺序，两次找出D的位置。

我们还没有分析完这个问题，因为在A、B、C的比较中你可能并不走运。也许比完前两次以后，你只知道A和C都比B好。那么面临着另一个困境：是比较A和C更优呢，还是用D来与A、B和C中的一个比较更优呢？考虑完各种情况及各种子情况，你还需要再观察，如果第二次比较的是C和D，情况会如何。

分析变得烦琐起来，但终究还是能够完成的。它表明，五次比较总是足够的，有时必须要比较五次之多，且第二次比较应当在C和D间进行。

这种论证的麻烦在于，要考虑的情况数量会急剧增加。譬如当对象有100个时，需要比较的确切次数是不可能算出来的——几乎可以确定这个数永远无从得知。（我犹记得，当我第一次听一位数学家宣称某个特定量的确切值永远无法算出，我当时有多么震惊。但现在我已经习以为常了，这是常有的事，并不是特殊情况。当时的那个数是拉姆齐数R（5，5），即为了保证n个人中必有五人全部两两认识，同时必有五人全部两两陌生，那么n至少是多大。）作为替代，我们要去寻找上界和下界。对于这个问题来讲，上界c

n

的意思是，对n个物体进行排序的某种过程至多进行c

n

次比较，下界b

n

的意思是：无论你有多聪明，有时候也必须要做上b

n

次比较才行。这个例子中，已知的最优上界和下界正相差一个乘数因子：相差常数倍情况下，对n个对象进行排序所需的比较次数为nlogn。

要理解这为什么有意思，你不妨自己构思一种排序过程。一种明显的方法是，先找出排序最靠前的对象放到一边，接下来再重复进行。为了找到最好的对象，先比较头两个，再将胜出者与第三个比，再将胜出者与第四个比，依此类推。这种办法下，需要比较n-1次才能找到最好的，再找出次好的需要比较n-2次，等等等等，于是总的比较次数为（n-1）+（n-2）+（n-3）+…+1，计算得约为n

2

/2。

尽管这种方法很自然，但如果你采用它，最终排列完时就比较了所有对象中的

每

一对，所以它其实是最低效的方法（虽然它的确具有易编程的优点）。当n很大时，nlogn是对n

2

/2很显著的改进，因为logn比n/2要小得多。

下述方法被称为“快速排序”，它并不能保证一定就会更快，但通常情况它都会快很多。它是如下递归（即利用自身）定义的。首先选择任一对象，比如x，再将其他对象分成两堆，一堆全都优于x，另一堆全都劣于x。这需要比较n-1次。接下来你只需分别对两堆进行排序——再次利用快速排序。也就是，对每一堆来讲，选出一个对象，将剩余对象分成两小堆，依此类推。一般来说，除非你运气很差，否则分出的两堆中对象数量是差不多的。于是可以表明，所需比较次数大致为nlogn。换句话说，这种方法通常都能以你期待的效率运作，相差常数倍以内。

【注释】

[1]

2013年，华人数学家张益唐证明了弱形式的孪生素数猜想。