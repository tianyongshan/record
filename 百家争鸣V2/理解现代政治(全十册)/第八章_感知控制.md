# 第八章_感知控制

理解现代政治（全十册）（严密论证，透彻分析，廓清现实，直面复杂 理想国出品）

第八章

感知控制

因为你创造了我的内心世界。

——《旧约·诗篇》139：13

在不让人民屈服于武力或审查的情况下，对人们施加权力的最后一种方式就是控制他们的所知、所想和准备就世界发表的看法。让人不去做某件事的好办法之一，就是从一开始就阻止他们做这件事的企图，或者是让他们确信，自己的欲望是错误的、不合法的、可耻的，甚至是疯狂的。

[1]

我把这种手段称为“感知控制”。

如果有可能创造一种对公开表达某种政治异见恶意满满的环境，那么人们就不太可能把这些不满带到台前。

[2]

如果你知道批评某位政客会让你泡着的酒吧陷入可怕的沉默，或者在社交媒体上引发一场“推特风暴”，对你进行人身攻击，那么你在发表批评意见时恐怕就会三思而后行了。

[3]

那些寻求权力的人善于将针对对手的偏见煽动起来。将某些问题完全排除在政治议程之外，就是一种权力。

[4]

有什么办法比创造一种仅是批评一下现状都是不可接受的环境还更有利于维持现状呢？

另一种通过感知控制来行使权力的方法是，从一开始就防止人们在某些方面产生不满。

[5]

这可能只是一个说服的问题，但也可能是欺诈的结果，比如审查制度，它完全阻断了人们对某些问题的关注。人们不可能对他们不知道的事情感到气愤。

更微妙的是，如果当权者能够制造出一种广泛的信念或传统智慧，即认为符合其利益的事情也符合其他所有人的利益，那么就不需要通过强制或审查来确保获得服从。

为了解超出我们直接经验的事物，我们须依赖他人去（a）寻找和收集信息，（b）选择什么值得报告或记录，（c）决定有多少背景和细节是必要的，（d）以易于理解的形式反馈给我们。这些工作都是在“过滤”。我们如何感知更广阔的世界，在很大程度上取决于我们可用来理解这个世界的过滤器。我们知道，经过过滤的内容通常只是事物全貌的一部分，但我们希望并相信，我们收到的信息是真实的，其最重要的方面已经得到优先考虑。

过滤是一种无比强大的感知控制手段。如果你控制了一个社会的信息流动，你就可以影响这个社会对是非、公不公平、干不干净、得体不得体、真实还是虚假、已知还是未知的共同观念。你可以告诉人们世界是什么样，什么是重要的，以及他们应该如何去思考和感受。你可以说明人们应该如何判断别人的行为。你可以唤起热情和恐惧、沮丧和绝望。你可以塑造规范和习俗，定义什么可以做，什么不能做，哪些礼仪是可以接受的，什么行为是适当的或不适当的，以及共享的社会仪式，如问候、求爱、仪式、谈话和抗议应该如何执行.什么可以说，什么被认为是不能说的.公认的政治和社会行为的界限是什么。如果我违反了一项规范或习俗，我可能不会像违反法律那样受到武力制裁，但后果可能会更糟：嘲笑、羞耻、排斥、孤立，甚至放逐。正如曼纽尔·卡斯特（Manuel Castells）所说：“我们感受和思考的方式决定了我们行动的方式。”

[6]

那些控制感知手段的人将更多地决定我们的感受和思考方式，进而决定我们的行动方式。

理解感知控制的作用有助于解释一个最经久不衰的政治学问题：为什么世界上那些“面带病容、积劳成疾和患有肺痨的穷苦人”很少起来反抗他们有钱有势的统治者。

[7]

马克思及其追随者，尤其是意大利思想家安东尼奥·葛兰西（Antonio Gramsci）给出的答案是，普通人在心理上已经习惯于被动接受自己的命运。

[8]

他们被幻想和错觉所控制，觉得改变是不可能的，甚至是不可取的。为了解释这一现象，人们提出了许多听起来很酷的理论，包括霸权主义、意识形态、错误意识和拜物教（不是不文明的那种）。马克思相信，假设有正确的历史条件，一旦世界的现实在工人阶级（“无产阶级”）面前揭示出来，他们就会联合起来推翻资本主义。马克思认为，知识分子的作用是帮助普通民众摆脱错误观念：“哲学把无产阶级当作自己的物质武器，同样，无产阶级也把哲学当作自己的精神武器。”

[*]

[9]

（我们将在第十三章更深入地探讨后真相政治和假新闻。）

20世纪的感知控制

在20世纪，过滤的日常工作主要由大众媒体完成：大量的公司通过印刷、广播和电视向数百万甚至数十亿消费者广播信息。重权在握的媒体公司和媒体大亨常常是人们关注的主题，人们担心这些公司可能会利用符合其自身利益和偏见的信息来操纵民意，或对消费者洗脑。尽管如此，除了国家面临极端危险的时候，英语世界的政治文化都强烈支持媒体的自我监管。

互联网的发明和广泛应用标志着传统大众媒体垄断过滤手段的终结。与旧系统相伴，一种“网络信息经济”出现了，在这种经济中，社交媒体和数字新闻平台使人们成为内容的生产者和批评者，同时也是消费者。

[10]

在21世纪头十年，人们普遍热情地对待这一发展。哈佛大学教授尤查·本科勒在《网络的财富》一书中预言，网络化信息环境的结果将是“更多的表达空间，其来源不同，质量也不同”：

不仅拥有言论自由，还能免受操纵，可以了解到多种意见……信息、知识和文化在根本上也更加多样化。

[11]

在某种程度上，这一预测是正确的，主要是因为前移动互联网时代的结构和文化依赖于自由和多元的信息流。

[12]

但正如我们将在第十三章看到的，新的信息环境也带来了自己的困境和问题，很难展开理性的思考。

重要的是要看到，互联网已经被用于更精确、更广泛地控制我们传递和接收的信息，从而控制我们感知世界的方式。有时，这仅仅是一个控制物理基础设施的问题——传输塔、路由器和交换机——信息通过这些基础设施传输。一个高压的国家想要在其管辖范围内审查互联网上所有的可用内容，甚至是创建一个独立的隔离网络，就能靠这种基础设施来完成。

[13]

本科勒承认，后来在智能手机上使用的无线互联网的基础结构，旨在使制造商和服务提供商能对内容进行更多的控制。

[14]

数字生活世界的感知控制

在未来，我们如何感知世界将越来越多地由数字系统向我们揭示或隐藏的东西所决定。当我们只体验到世界的一小部分时，呈现在我们面前的那一部分将起到重大作用。它将决定我们的所知、所感和想要什么，从而影响我们去做什么。控制以上途径就是政治的本质。

新　闻

第一个被数字技术控制的感知方式就是新闻。我们已经越来越依赖社交媒体来分类和呈现新闻。数字时代的新闻与现在不同，传统上从事过滤工作的记者、作家、编辑和版主将逐渐被自动化系统取代。算法过滤器能够以你最喜欢的形式给你推送特定的内容：给正在洗澡的你大声朗读（新闻），播放简短的全息剪辑，在增强现实或虚拟现实中给新闻赋予生命，甚至是以优美的古文形式呈现出来。它还能满足你了解适量细节和语境的需求。算法过滤的主要承诺是为我们每个人量身定制一个信息环境。如果你相信代码的话。

新闻自动化的进程已然开启，自动化的文章生成、自动化的评论审核，以及自动化的编辑来决定你看/不看什么新闻。就像亚马逊和网飞（Netflix）推荐你应该消费的书籍和电视节目一样，直到最近，据说你在Facebook新闻平台上看到的新闻是由该平台通过权衡约10万种因素决定的，包括点击、点赞、分享、评论和发帖人的受欢迎程度，你与发帖人的特定关系，你一般对什么主题感兴趣，以及该话题所呈现出的相关性和可信度。

[15]

搜　索

第二，当我们搜索信息时，过滤器就会起作用。搜索引擎决定哪些结果或答案应该优先响应我们的查询。谷歌页面排名方法的具体细节尚不可知，但一般认为它根据特定查询的相关性和重要性来对站点进行排名，部分取决于某网页被其他寻找相同信息的搜索者关联起来并点击的频率。在谷歌搜索中排名靠前这件事的商业和政治重要性，怎么强调都不为过。90%的点击产生于搜索结果的第一页。如果你或你的企业的排名太低，那么从信息的角度来说，你可能就是“不存在”的。

[16]

未来，搜索系统将能够更好地解析用自然语言提出的问题，因此当你“看”某样东西的时候，就不太像是在扫描一个庞大的数据库，而更像是在咨询一位无所不知的私人助理。

[17]

这些神谕系统将决定什么是你需要知道的，什么是不应该知道的。就像新闻一样，不能保证你得到的信息和我得到的信息是一样的.它可以根据系统判定的与我们最相关的内容进行调整。

通　信

第三，无论我们何时使用数字方式进行交流——在数字生活的世界中，这是十分常见的——我们同时也就在这个系统中向“过滤”开放了。举一个基本的例子，我们的电子邮件消息系统已经使用算法来确定哪些是垃圾邮件，哪些不是（当得知某人的电子邮件系统认定你的邮件是“垃圾邮件”时，总会令人隐隐感到不安）。中国版Skype的用户被该应用程序的代码禁止相互发送某些术语。

[18]

这反映了一种更广泛的趋势，即通信技术受制于基于禁用词的即时审查。微信是世界上第四大聊天软件，有近9亿的月活跃用户

[†]

，它会根据关键词进行审查。如果你发送的消息中包含禁用词，远程服务器将通过审查系统直接拒绝发送该消息（而你并没有被告知）。

[19]

以前，人类官员觉得实时审查谈话内容只是个梦想。我们的交流过程也能以更微妙的方式形塑。例如，苹果公司决定从其设备上的信息应用程序中删除枪支表情符号，这是一项有趣的努力，目的是监督人们的言论，进而监管他们的行为。

[20]

情　绪

第四，数字技术将对我们的感受和认知产生日益明显的影响。Facebook最近进行的一项研究表明，数字技术可以通过过滤“积极”或“消极”的新闻内容来影响用户的情绪（有争议的是，这项研究是在受试者不知情或没有征得其同意的情况下进行的）。

[21]

而这仅仅是个开始：越来越敏感的技术将能够有效地感知和适应我们的情绪。有着能灵敏地回应我们需求的“面孔”和“眼睛”的人工智能“伙伴”充斥在我们周围，它们或许还能以其他方式激发我们的情感，我们的感知方式将牢牢掌握在技术手中。我们也将越来越受制于技术规范和习俗的约束，它们鼓励我们以特定的方式行事。在创作可能产生流量或得到“病毒式传播”的内容方面，写作者已经感受到了压力。对年轻人来说，在Twitter上吐露自己的内心想法，在Instagram上展示自己的生活和身体，在Facebook上表达自己的好恶，都能获得社会回报。

即时的感官体验

最后，以前只有当我们试图了解视线之外的事物时，外部过滤器才会真正发挥作用，但在未来，我们会越来越多地将我们的直接感官体验提交给过滤器。我曾在第一章中解释，增强现实技术通过计算机生成的输入，如声音、图像或视频来增强我们对物理世界的体验。智能眼镜（以及最终基于视网膜的增强现实技术）可能会为我们的所见提供一种视觉覆盖.耳机也是如此。随着技术越来越先进，即便你同时体验现实与虚拟，想要区分它们也将变得越来越困难（或毫无结果）。如果增强现实或虚拟现实系统真的取代了“玻璃平板”计算模式，这种过滤形式的重要性就会上升。

我们看到了什么，什么被屏蔽了，哪些情感被激发，哪些没有被触动——我们将把这些决定托付给为我们过滤世界的设备。一个把无家可归者从视野中抹除的世界，意味着在这个世界中，无家可归者的政治重要性很低。

[22]

你的智能视网膜根据你伴侣身体发出的信号向你提供她的实时信息——她的笑容真诚吗？她紧张吗？她对你来电吗？由于这种技术的存在，你们喝酒约会的结果可能是天差地别的。控制我们感知的这种力量，将使试图控制我们的人的武器库如虎添翼。

感知控制：含意

有人说“治理就是选择”，反之亦然，“选择就是治理”。每当一个算法选择讲述哪个新闻故事，或确定搜索结果的优先级时，它也必然会漏掉一些信息。例如，根据点击量和受欢迎程度对新闻或搜索结果进行优先排序的方式，必然会排除或边缘化那些不太主流的观点。它鼓励出现轰动效应。未能应对假新闻也是一种选择，这使得提供假新闻的人可以发挥影响力（第十三章）。我们在本书中看到，以我们的自由、民主和社会正义的要求为背景，那些看似技术上的决定往往是政治上的决定。

当然，从另一方面看，社交媒体和社交网络平台也为普通人提供了发声的途径。像“阿拉伯之春”和“占领华尔街”这样的政治运动在动员和组织上深度依赖此类技术。但这些例子只是强调了一个更深层次的问题，即当我们使用社交媒体交流时，是受制于那些控制这些平台的人的。我们在他们的许可下，遵循他们的条件进行交流。使用他们的代码，遵守他们的规则。

生活在一个逐渐将感知控制委托给数字技术和控制它的人的世界里，有什么更深层次的含意呢？当然，因世界被过滤方式的不同，我们看待世界的方式也各不相同，社会分裂的问题就出现了。本书第四部分会讨论其中一些问题。

它还是一个合法性问题，这个问题将贯穿全书。我们似乎相信科技公司会以公平和公正的方式过滤世界——但如果它们不这样做呢？数字生活世界才刚刚起步，很多迹象却足以引起我们的不安了。例如，苹果公司就曾阻止或拒绝支持批评其制造商工作条件的应用程序。

[23]

你在使用搜索引擎时，很难判断搜索结果是公司竞价排名买来的，还是玩弄算法得来的。

[24]

让他人有能力控制我们的感知会有不少问题，有出现极端结果的风险即其一。2009年，在与一家出版商发生龃龉后，亚马逊进入了每一款Kindle设备，并在未经允许的情况下删除了某本书的副本。这一壮举之所以成为可能，是因为电子阅读器使用了云存储技术。这本书的书名很应景——乔治·奥威尔的《1984》。

[25]

如果时间倒回1995年，印刷书商想立即召回已经卖出去的数千本书自然是不可能的。不难想象，一位缺乏安全感的总统会试图阻止人们访问有关他过去交易的特定信息。

现在想象一下，你的新闻和搜索过滤器，以及你的增强现实设备，都是由一家叫德尔斐的技术公司运营的。有一天，一位政客认为德尔斐公司已经变得过于富有和强大，她的参选理由即源于该公司应该被拆分，并应以更高的税率征税。德尔斐的高管认为，这位政客的提议对公司的生存构成威胁，因此决定采取激进行动来保护自身的地位。随着时间的推移，人们谈论的这位政客已从大众视野中消失。人们几乎收不到任何有关她竞选活动的消息，即使收到了什么消息，也不会是好消息。当人们用德尔斐公司的“搜索神谕”查询“选举候选人”的信息时，该政客作为候选人的事实不是被忽略掉或当作备选，就是饰以令人不快的事实。那些亲自听过她讲话的人发现，他们的增强现实滤镜让她的声音听起来毫无吸引力。在这轮博弈中，政客输给了科技公司，现状却保持不变。这个颇具代表性的例子，就是哈佛大学教授乔纳森·齐特林（Jonathan Zittrain）所说的“数字化的选区不公正划分”（digital gerrymandering）

[‡]

，它结合了对数字生活世界中感知方式之力量的诸多担忧。

[26]

它表明，尽管权力可以被用于积极的目的，如让人们充分了解信息等，但也可以用来创造一个对特定想法充满敌意的环境，从公众意识中消除或降低某些问题的声量，从而促进不考虑公众利益的规范和习俗的形成。

如果一个算法显著地扭曲了我们对世界的看法，导致我们持有原本可能没有的信念，或拥有原本可能没有的感觉，或者去做我们本来不会去做的事，那么我们甚至很难意识到施加在我们身上的权力的本质。我们不知道自己不知道什么。过滤器滤掉了对强者进行审视的必要视角。

[*]

此处译文参考了《马克思恩格斯选集》第一卷（人民出版社，2012年）中译本相关段落。——译注

[†]

截止到2019年9月，微信月活跃账户数为11.51亿。数据来自《2019年微信数据报告》。——译注

[‡]

指的是通过操纵选区边界来制造某政党的政治优势。齐特林对“数字化的选区不公正划分”的定义为：通过由媒介进行的信息选择性展示来满足媒介的议程，而非为其用户服务。参考：Zittrain, J. (2014). “Engineering an Election: Digital gerrymandering poses a threat to democracy”.

Harvard Law Review

, 127(8), p.336.——译注