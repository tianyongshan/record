# 第十一章_科技公司与自由

理解现代政治（全十册）（严密论证，透彻分析，廓清现实，直面复杂 理想国出品）

第十一章

科技公司与自由

让每一个国家知道，不管它希望我们好还是希望我们坏，我们将付出任何代价，承受任何负担，应付任何困难，支持任何朋友，反对任何敌人，以确保自由的存在和自由的胜利。

——约翰·F. 肯尼迪在1961年的就职演说

马基雅维利（Niccolo Machiavelli）在《君主论》中写道：“古代的人比我们今天的人更热爱自由。”

[1]

这已经是五百年前的事了。在那时，对“共同自由”的最大威胁是国王、殖民和征服。在未来，还会有第四个威胁，那就是代码。

数字技术不仅会使国家处于增压状态，还会使越来越多的权力集中在控制技术的科技公司手中。让我们回顾一下托克维尔在《论美国的民主》一书中对这部分内容的描述：“每个人让自己戴上项圈，因为他明白，握住链子末端的不是一个人，也不是一个阶级，而是社会本身。”而在数字生活的世界里，情况并不总是如此。数字权力的“项圈”，并不系于国家，而往往是由一个非常特殊的“阶层”控制，即由控制技术的公司控制。本章致力于理解这对自由意味着什么。

我的观点很简单：如果科技公司拥有影响我们最宝贵的自由的力量，那么它们也必须理解和尊重自由的某些基本原则。人类已经花了几个世纪来发展这些原则。在什么情况下允许限制一个人的自由？我们可以自由地自我伤害吗？是否应该阻止我们做出不道德的行为？这些问题不能仅仅被视为企业或商业问题。它们是政治理论的基本问题。

自由和私人权力

正如我们所见，数字技术有一个奇怪的特质，它可以同时增强和限制我们的自由。它使我们可以自由地去做以前不能做的事情，但同时也根据代码的约束限制我们的行为。想一想你用过的苹果设备，它通常是富于美感的：光滑、流畅和直观。它提供了大量的应用程序。但这是一个由苹果闭环设计的世界，你不能根据自己的喜好对其重新编程，只能使用苹果公司选择的应用程序，而苹果公司对应用程序开发者的指导方针是：

我们将拒绝任何我们认为过分的内容或行为。你可能会问，哪里过分了？嗯，正如一位最高法院法官曾经所言，“看过即知”。

尽管这一条款有些武断，但抱怨它还是显得有些无礼。苹果设备为用户提供了大量选择，系统运行良好。法律学者吴修铭（Tim Wu）在提到这个例子时指出，“从总体上看，消费者似乎满足于为了方便而忍受一点极权主义”。

[2]

吴修铭的说法是正确的。我们凭直觉理解，苹果设备整体上给我们带来了更多自由，即使我们不能用它做到任何我们想做的事。问题是，同样的取舍在数字生活世界中是否仍然有意义，这个代码帝国将扩展到几乎所有我们当下认为理所当然的自由。

以言论自由为例，这是一种最神圣的自由。言论自由允许真实的自我表达。它保护我们不受强大利益集团的侵害，也使它们暴露在批评和嘲笑之下。它允许“反对意见的碰撞”，这是追求真理的必要过程。

[3]

除了一些例外，我们大多数人都会对政府审查我们的言论或表达方式这一想法感到恐惧。我们崇敬希腊集会的理念，在那里，公民自由、无畏、平等地发言（见第十二章和第十三章）。

在数字生活世界里，几乎所有言论都将由私人科技公司中介和调节。这是因为，我们与熟人或是生人的交流，都将几乎完全依赖私人公司提供的平台。这意味着科技公司将决定可用的通信形式（例如，图像、音频、文本、全息图、虚拟现实、增强现实，以及不超过140个字符等）。它们也会决定我们交流的对象，包括可以联系谁（仅限网民？），以及如何根据相关性、流行度或其他标准对内容进行排名和排序。它们甚至会决定我们表达的内容，禁止它们不认可的言论。这涉及一些微妙的区别。根据《卫报》获得的泄密文件，Facebook不会删除一篇内容为“掐住婊子的脖子，确保你所有的压力作用在她喉咙的中间位置”的文章，但它会移除讲“有人向特朗普开枪了”的内容，因为总统作为国家首脑，处于受保护的范畴。堕胎的视频显然也是可以发布的，除非其中包含裸露镜头。

[4]

有能力限制言论的不仅仅是社交媒体平台。在发言者和受众之间通常还有其他一些技术中介，包括控制信息传递硬件的公司。

[5]

不管精准程度如何，每一方都能或多或少地控制信息流。

简而言之，我们正在目睹一种新的、历史性的政治平衡出现：我们获得了全新的发言形式和机会，但作为交换，我们也要接受一个事实，即我们的言论必须遵从控制论坛的人制定的规则。这就好像雅典的城市广场已经私有化，被一个雅典寡头收购，这个寡头因此有权决定辩论规则，选择谁可以发言和发言多长时间，以及决定哪些话题是禁止讨论的。这两者主要的区别在于，平台的算法监管意味着，每天会有成千上万个影响我们言论自由的决定做出，这些决定是自动做出的，并且无障碍执行，人们没有上诉的权利。例如，微软、Twitter和YouTube最近联手宣布成立全球互联网反恐论坛。在其他措施中，他们将“共同改进和提升现有的技术联合工作”，包括使用机器学习技术进行“内容检测和分类”。

[6]

现在，许多人将乐于让科技公司承担规范言论的任务。但既然这是一个关于自由的章节，我们就有必要回顾一下共和主义的自由原则：依赖于强权约束的自由根本不是自由。每个控制言论平台的公司，只要它们愿意，可以随时减少或改进我们的言论自由。这种关系就像革命前的英国人和美国人一样，我们的言论自由的生存依赖于他们的一时兴起和爱好。从政治上讲，这令人满意吗？

这不仅仅关乎言论。让我们总体思考一下思想自由问题。我们已经相信科技公司能够找到和收集关于这个世界的信息，选择值得报道的内容，决定有多少背景和细节是必要的，然后以易于理解的形式反馈给我们。不带任何附加条件，我们赋予它们一种力量，以塑造我们对是非、公平与不公平、洁净与不洁净、得体与不得体、真实与虚假、正确与错误和已知与未知的共同认知。简而言之，我们让它们控制了我们对世界的感知。这对思想自由来说是一件大事。

现在来考察一下另一种基本自由：行动自由。自动驾驶汽车显然将带来有价值的新功能。开车行驶在道路上的不一定是司机了。公路运输将更安全、更快，节能性也更好。乘客可以在行驶途中工作、吃饭、睡觉或社交。然而，为了换取这些功能可供性，我们必须牺牲其他自由：（偶尔）超速驾驶的自由，（偶尔）在双黄线上非法行驶或停车的自由，不留下任何记录的旅行自由，甚至还可能是做出道德选择的自由，比如（在第六章中描述的电车问题中）是选择撞死孩子还是撞死卡车司机。再说一次，我并不是想说这是一笔不值得敲定的交易。但我确实建议我们看清它的本来面目：它本身就是一种交易，人类最宝贵的自由就是其交易的一部分。

从自由的角度来看，国家所掌握的权力与科技公司所掌握的权力有四个重要区别。

第一，也是最明显的是，民主国家要对人民负责，公民也对管理他们的规则有实质意义上的发言权。权力可以被问责。但对于大多数私营科技公司来说，情况却并非如此。它们制定规则，我们接受规则。你想想，自己虽拥有一台设备，但这并不一定意味着可以控制它。数字生活世界中的大多数技术都将在远处被重新编程。我们的财产可以在我们眼皮底下，在未经我们同意甚至毫不知情的情况下被用于其他目的。

第二，（至少在理论上）国家的存在是为大众利益服务的。一个运作良好的政府制定旨在促进共同利益的法律和政策。相比之下，科技公司就像所有以资本主义模式运营的私营公司一样，为其所有者的商业利益而存在。

第三，成熟的法律制度是根据明确的规则和准则，随着时间的推移系统发展起来的。相反，私有代码以一种特殊的、不一致的方式开发出来。不同的公司采取的方式各不相同：Facebook可能会审查Twitter认为可以接受的内容.一个应用程序可能会收集你的个人数据，另一个可能不会.你的自动驾驶汽车可能会撞死孩子，而我的车可能会突然转向，撞死卡车司机。代码帝国并不是一个统一的领域，而是由一些重叠的管辖区拼凑而成的。这并不一定是件坏事，它可能会形成一种数字邦联主义，人们可以根据自己喜欢的代码在不同的系统之间游走。我们稍后会对其详细介绍。

第四，数字生活世界中技术的复杂程度令人无法想象，比政府的运作方式更加难以捉摸。这一点至关重要。塞缪尔·阿贝斯曼（Samuel Arbesman）观察到，一架波音747-400飞机——已经是一个相当老旧的装备——也有600万个独立部件和275千米长的线路。

[7]

但是，与将要发生的事情相比，它只能算是小儿科了。未来将充斥着各种组件和新奇的发明、设备和传感器、机器人和平台，这些平台包含着数不清的数万亿行代码，这些代码将以越来越快的速度复制、学习和进化。有些系统将完全在“人类知识和理解之外”运行。

[8]

机器的功能与人类不同，这一事实使它们天生难以理解。但在通常情况下，它们甚至不能根据其设计来运转。就像父母对孩子文身的决定感到困惑一样，软件工程师也经常对自己的人工智能系统做出的决定感到惊讶。随着算法越来越复杂，它们也变得越来越神秘。许多系统已经运行了数千行自生成的“黑暗代码”，其功能未知。

[9]

将来，甚至可以越来越多地听到来自技术创造者们的发问：它为什么要这样做？它是怎么做到的呢？对于我们这些不懂技术的人来说，数字生活世界的技术运作将是完全不透明的。

让技术变得不可思议的不仅仅是其复杂性。我们经常被有意地阻止去了解它们是如何工作的。代码通常是有商业价值的，它的所有者会利用一切可用的手段使其不被竞争对手发现。正如弗兰克·帕斯奎尔（Frank Pasquale）在《黑箱社会》（

The Black Box Society

，2015）中所说，我们逐渐被“由律师围成人墙来保护”的“专有算法”所包围，从而使得这些算法“不受审查，除非碰到检举人提起诉讼或泄密这种极少数情况”。

[10]

此外，在数字生活的世界里，经常会有一些时候，我们甚至没有意识到权力正施加于我们。许多监控技术都在后台悄然运行。如果一个新闻算法巧妙地倡导和推广了某一种叙述而不是另一种叙述，或者隐藏某些故事，我们又从何得知呢？未来，最好的技术不会让人觉得太过于引人注意，它会一点也“不技术”。正如丹尼尔·索洛（Daniel Solove）所说，风险在于，我们会发现自己身处一个卡夫卡和奥威尔式的世界，在巨大的、不可知的、通常是看不见的力量面前，总是表现得“无助、沮丧和脆弱”。

[11]

鉴于未来科技公司将不得不塑造和限制我们的自由，我们有必要回到社会应该允许和不应该允许的基本原则上来。我们宝贵的自由被托付给某些人，这些原则应该用来指导他们工作。

伤害的原则

约翰·穆勒是思想史上的一位杰出人物。作为苏格兰著名哲学家詹姆斯·穆勒（James Mill）的儿子，年幼的约翰·穆勒被有意地与除兄弟姐妹以外的孩子隔绝开来，并接受了严格的教育。他在1873年出版的自传中写道：“我不记得从何时开始学习希腊语，听说是在三岁的时候。”

[12]

他八岁那年开始学拉丁语。

[13]

他自幼就与“边沁先生”争论问题，边沁是他父亲的朋友，也是西方哲学中最重要的思想家之一。年轻的约翰·穆勒显然是个天才，但老穆勒没有让他过早知晓这个事实。他以“极度警惕”的态度避免儿子听到别人对他的赞美之词。

[14]

穆勒成长为一位尽精微而致广大的思想家，一生致力于个人自由的理想。以赛亚·伯林观察到，成年后的穆勒最害怕的就是“心胸狭隘、整齐划一、压迫戕害，用权威、习俗或公共舆论碾压个体”。他拒绝“推崇秩序或整齐，甚至和平”，他喜欢“未被驯服的人类的多样性和色彩，它们充满着不灭的激情和无拘无束的想象力”。

[15]

穆勒远远领先于他所处的时代。在被维多利亚时代严格的道德主义

[16]

定义的时代，他无畏地倡导个人主义，而不是“从众”和“平庸”。

[17]

作为一个三岁就开始学习古希腊语的人，他认为其时代主要的危险是“现在很少有人敢做一个特立独行的人”。

[18]

穆勒是个开明人士

[*]

，但不是自由论者。他承认，为了社会的延续，必须对个人自由施加超过最小限度的限制（如果你愿意，可以称之为明智的限制）。但他相信，想要限制他人的自由，须有充分的理由。他开始认识到，只有一个理由可以证明这种限制是合理的：防止伤害他人。这就是伤害原则，西方政治思想中最具影响力的观念之一。这是穆勒的《自由论》的核心部分：

对文明社会的任何成员，在违背其意愿的情况下，正当地行使权力的唯一目的，是防止对他人造成伤害……对他自己，对他的身体和心灵，个人是至高无上的。

[19]

后来的自由主义思想家改进了对伤害原则的论述。例如，在乔尔·范伯格（Joel Feinberg）的表述中，只有那些造成“可避免的实质性损害”的行为才可以被理所当然地禁止。

[20]

不幸的是，伤害原则在历史上一直被肆意违背。从一开始，人们就因为持有“错误”的信仰而受到迫害，因为与“错误”性别的人做爱而受到惩罚，因为向“错误”的上帝祈祷而遭到屠杀——这其中没有一件事伤害到了其他人。在数字生活世界中，科技公司必须比过去握有权力的强者做得更好。这是我们构建人类自由的机会，其目的应是解放人们，而不是摧毁他们。

自我伤害

想象以下四个场景。

第一个场景，伊娃给别人写了一封邮件，内容包含侮辱劳拉的言辞，结果却不小心把邮件发给了劳拉（我们都有过这样的经历）。幸运的是，一个自动提示立即弹出：“系统检测认为此人可能不是预定的收件人。发送/修改？”伊娃怀着感恩的心情纠正了自己的错误并重新发送了邮件。电子邮件系统对伊娃的自由施加了限制，一旦她按下“发送”键，邮件就会被扣留。但这种限制是暂时的，性质上是次要的，也能够立即被推翻。这使她免于陷入一种相当难堪的境地。我想，大多数人都会欢迎这类对我们自由的干涉。

接下来看看詹姆斯，他超重了几磅。夜深了，他饥肠辘辘，就蹑手蹑脚地来到厨房，打开“智能”冰箱，取出一大块馅饼。他流着口水，手拿馅饼站在水槽边以防馅饼渣掉得到处都是，正打算大快朵颐，突然间，冰箱大声地嘲讽他：“詹姆斯，你真的需要那块饼吗？”他又震惊又羞愧，赶紧把馅饼塞回冰箱，自己溜回床上。就像伊娃的电子邮件提醒一样，詹姆斯无礼的冰箱让他改变了行动方式（或者，从权力的角度来说，让他克制自己不去做一些本来会做的事情）。没错，冰箱并没有强迫詹姆斯不要吃馅饼，但它的监督也产生了同样强烈的规训作用。我猜大多数人会对这种来自他人的干扰感到不适，更不用说是来自某个厨房电器的干扰了。即使是为了我们好，它们管得也太宽了，让我们觉得多少有点被冒犯。当然，如果詹姆斯以奥德修斯式的自我克制（见第十章）来要求冰箱监督他的饮食习惯，情况又会有所不同。

再想象一个叫尼克的人，他指导其食物准备系统（我们叫它“机器人大厨”）

[21]

根据他准备的食谱做一盘咖喱菜。然而，尼克提供的食谱中在辣椒用量上出现错误，导致辣椒含量过高，高到足以让尼克整个晚上都处于极度不适的状态。机器人大厨检测了到这个不成比例的数字，于是选择忽略它，采用适量的香料做出了美味的印度咖喱菜。尼克享用了这道美味，那么他应该如何看待机器人大厨的介入呢？不可否认，机器人大厨是在按照尼克的利益行事（它正确地认识到了这一点）。但它在没有知会尼克的情况下违背了他的指示，没征求主人的意见就假定了他的利益，这便让人有些不安了。如果菜谱中辣椒的用量并没有错呢？也许尼克就是那种爱吃辣的人呢？——管不了胃舒服不舒服了！如果他直接让机器人大厨提供一道真正超级辣的咖喱菜——对大多数人都有害——机器人大厨拒绝做这道菜会是对的吗？换句话说，一个数字系统是否应该拒绝一个具有完全行为能力的成年人在自愿并知情的情况下选择的后果呢？

最后，想象一位上了年纪、深受慢性疾病折磨的绅士，我们姑且叫他格雷厄姆。他孤身一人却心态平和，真心希望结束自己的生命。为此，他指示他的机器人大厨准备一种致命的氰化物汤。机器人大厨拒绝了他的要求。于是，格雷厄姆沮丧地躺在车道上，命令他的自动驾驶汽车从其头骨上碾过。汽车也礼貌地拒绝了他的要求。绝望之下，格雷厄姆试图服药自杀。但他的“智能”楼层系统检测到他躺在地板上失去知觉的身体，并自动向紧急服务机构发出呼叫。

[22]

格雷厄姆的生命再次被挽救，这显然违背了他的意愿。

在上述所有情境中，数字系统都会进行干预，以约束人类的意志或行为，尽管其方式在本质上可能是好的，其目的也是保护人类不致自我伤害。我们可以称之为“数字家长主义”。数字家长主义应该在多大程度上成为数字生活世界的特征？数字系统应该纵容还是保护我们？我们能猜出约翰·穆勒会怎么说。他认为，一个人“自身的利益，无论是物质上的还是道德上的”，从来都不是对他行使权力的“充分理由”。只有伤害他人才能证明这一点。

[23]

但是，在一个对自由施加小小限制就能带来真正好处的世界里，穆勒的原则似乎有些狭隘。艾萨克·阿西莫夫（Isaac Asimov）著名的“机器人第一定律”与穆勒的观点大相径庭，该定律规定，机器人不得伤害人类，也不得坐视人类受到伤害。但是，阿西莫夫也清楚，第一定律本身并不足以指导行动。它并没有告诉我们为了保护人类，机器人必须走多远。它也没有说明什么才算是伤害。个人的尴尬？一块不健康的馅饼会引起心脏病吗？超级辣的咖喱菜？还是死亡？

在这四种情境中，格雷厄姆的假设最简单，也最令人烦恼。在大多数发达国家，自杀早已不再是犯罪。一般而言，一个人协助另一个人死亡或致残是非法的.因此，在大多数国家，你不能参与安乐死，不能给人注射海洛因，不能因施虐受虐的性爱行为而对他人造成严重伤害。受害人的许可也不能为你辩护。但格雷厄姆并不是在寻求其他任何人的帮助。相反，他的死在道义上并不需要牵连除他以外的任何人。他只有一个愿望——去死，而且他认为可以通过技术手段来实现这个愿望。然而，这种技术要么拒绝帮助他实现目标，要么就积极地阻碍它。这不是对格雷厄姆自由的严重侵犯吗？也许是这样，但你如果认为自由是唯一的价值，那就错了。允许机器协助自我伤害（或在伤害发生时袖手旁观）可能会威胁到“社会赖以建立的伟大道德原则之一，即人类生命的神圣性”。

[24]

从这个观点来看，格雷厄姆的自杀可能不是针对他自己的犯罪，而是对“整个社会”的冒犯，这是不能容忍的，即使这意味着使格雷厄姆和跟他情况类似的人更不自由。

[25]

我认为，在穆勒所拥护的自由和数字家长主义的好处之间，可以取得富有成效的平衡。上述情境表明，在决定是否应该限制自由以防止自我伤害时，至少要考虑11个因素。被剥夺的自由有多重要？相比之下，所寻求的益处有多大？被限制的是一种自愿的、有意识的和知情的选择，还是一种偶然的、本能的，或者非自愿的行为？这种约束是公开的还是隐蔽的？这种约束的施加根据是我们明确表达的利益，还是仅仅是我们被感知到的利益？它是否涉及武力、影响或操纵（也就是说，它是否为自由选择留下了适当的空间）？约束是一种忽视还是一种行动？它能被推翻吗？它持续了多长时间？自由受到限制的人是成年人还是未成年人？他/她是否拥有正常的心智？

界限必须要划定，但这个问题是政治性的，不是技术性的。

不道德却无害

每个社会对于什么是邪恶、错误、有罪和不道德都会产生某些共识。一个长期存在的问题是，我们是否应该被允许做一些不道德却无害的事情。举个例子，一个有恋童癖幻想却从未伤害过孩子的人（事实上，一个人有这种想法本身就会让人反感）。一个男人有可能私下里和他父亲发生自愿的性行为，而不会伤害任何人。这种事情应该被禁止吗？如果这种事见了光，他们应该受到惩罚吗？这些问题在以前纯属法律和道德的范畴。在数字生活世界中，它们也将是代码问题。

想象一个为用户提供身临其境体验的虚拟现实平台。头戴设备和耳机提供视觉和声音。气味是由嗅觉气体和气味油合成的。通过“触觉”套装和手套以及适当形式的定制道具来刺激身体接触。当体验需要产生性刺激时，有专门设计的“电子爱抚装”（teledildonic）设备提供。

[26]

该系统甚至能够对通过脑电图（EEG）检测到的脑电波做出直接反应。

[27]

它被用于家庭的私密空间。只有用户才能看到他们的虚拟冒险，哪怕制造商也收不到这些信息。

你会选择用这种技术做什么？在超级碗比赛中投出制胜一球？与拳王阿里面对面交手？还是和弗雷德·阿斯泰尔（Fred Astaire）跳舞？

相反，如果你想“体验”在奥斯维辛当纳粹刽子手的感觉呢？或者以第一视角再现“9·11”劫机者之一穆罕默德·阿塔在生命最后一天的场景呢？用户应该在虚拟现实中模拟淹死小狗或勒死小猫的行为吗？他们应该被允许折磨和残害他们邻居的虚拟化身吗？强奸儿童的“体验”呢？在虚拟现实中，有可能知道把耶稣钉上十字架是什么感觉吗？

对大多数人来说，连想想这些场景都是可怕的。它们严重冒犯了我们共同的道德感。这正是我们必须思考这些案例的原因。衡量一个社会对自由的承诺，不在于它对道德主流内的行为有何看法，而在于它对那些被认为是不可言说的、淫秽的或禁忌的行为必须说些什么。

我们很可能同意，选择在虚拟现实中体验以上经历本身就可能腐蚀人们的道德品质。这是对自己的一种伤害。但实际上并没有人被肢解、强奸或侵犯。如果你认为社会无权监管人们的私人道德，那么你可以顺理成章地得出结论：在虚拟现实中，任何事情都应该被允许。只要没有对别人造成伤害，就应该让人们为所欲为。毕竟，在自己的内心深处幻想这些事情并不能遭到禁止。使用虚拟现实不也差不多吗？

一些哲学背景有助于深入思考这个问题。

长久以来，惩罚人们的思想活动被认为是一种糟糕的形式。我们看到，在19世纪，约翰·穆勒认为社会无权禁止只影响个人的行为。与穆勒同时代的一位法官詹姆斯·斯蒂芬（James Fitzjames Stephen）持不同看法，他认为，我们有充分理由“不仅对他人的行为感兴趣，而且对他人的思想、感受和意见感兴趣”。

[28]

一个世纪之后，在H.L.A. 哈特和德夫林（Patrick Devlin）发生于20世纪60年代的著名辩论中，同样的分歧再次出现。哈特是典型的自由主义法学教授，他性情温和，才智过人，举止文雅。德夫林全然收起了他固执的个性。与斯蒂芬一样，德夫林也是一名法官。哈特和德夫林的辩论是由同性恋犯罪和卖淫委员会在1957年发表的报告引起的，该报告通常被称为《沃尔夫登报告》（Wolfenden Report）。该报告的著名结论是，“法律没有义务关注不道德行为”：“必须保留私人道德和不道德的领域，简单粗暴地说，这与法律无关。”

[29]

德夫林不同意报告的结论。他认为社会是一个“思想的共同体”，不仅仅是政治思想，还有“关于其成员应该如何行动和管理其生活的思想”。

[30]

也就是说，每个社会都必须有共同的道德，否则社会就不可能存在。

[31]

允许不道德的行为不受惩罚，即使这些行为对他人没有明显伤害，也会降低维系人们团结的道德结构。他在1965年写道：“在1940年，一个堕落的国家不会令人满意地响应温斯顿·丘吉尔的号召，付出热血、辛劳、汗水和泪水。”

[32]

哈特承认，任何社会的存在都需要某种共同的道德准则，起码是为了限制暴力、盗窃和欺诈。但他驳斥了德夫林的观点，认为法律与规范道德无关。哈特认为，没有证据表明成年人在私下违背“公认的性道德”“像叛国一样威胁社会存在”：“事实上，它不应该比‘查士丁尼皇帝称同性恋是地震起因’的声明获得更多的尊重。”

[33]

对哈特来说，我们的个人选择，尤其是那些私下做出的选择，与我们是不是忠诚的公民没有关系。［哈特本人曾毫不犹豫地响应丘吉尔的号召，因为他在二战的大部分时间里都在军事情报部门工作。同样，在布莱切利公园工作过的伟大数学家、密码破译者艾伦·图灵（Alan Turing），也曾因同性恋行为受到刑事起诉。］

哈特和德夫林之间的辩论如果放在今天，将会如何展开呢？

首先，我们可能会认为虚拟现实实际上与纯粹的幻想大不相同。它的现实感和感官上的真实性使它更接近于实际在做某事，而不仅仅是思考。这个论点的问题在于，如果你像穆勒和哈特那样，在原则上相信，单纯的不道德绝不应该成为强制的对象，那么，说某件事“非常不道德”，而不仅仅是“比较不道德”，也没有太大意义。

另一个论点是，如果我们允许人们在虚拟现实中做出极端行为，那么他们也许更有可能在“真正的现实”中这么做。虚拟现实中的暴力性体验可能会鼓励实际性暴力的发生。这是一个可以通过实验验证的经验主义论点。此前的研究表明这是很有可能的。

[34]

如果虚拟行为确实导致了真实行为，那么根据伤害原则，禁止某些虚拟体验就是合理的。也就是说，如果我的淫秽虚拟现实体验只涉及对我个人的虚拟伤害，比如一个被暴力控制的幻想，那么我显然不会出去伤害其他人。

第三个更加德夫林式的反对意见是，虚拟现实中不受约束的自由可能严重腐蚀共同的道德，或者人们传统的生活方式。

[35]

另一种说法是，自由应该被构建为能“提升或完善人类性格”，而不是去降低它。

[36]

有趣的是，一项早期研究表明，能够在虚拟现实中飞行的体验会鼓励现实世界中的利他行为，这显然是触发了对超人这样的空中超级英雄的联想。

[37]

这一论点的另一种变体是，没有一种道德体系在本质上比另一种好，但同一个共同体内存在多重道德确实是个问题。正如德夫林所说，如果没有“关于善恶的基本共识”，社会就会“解体”。因为社会不是一个在物理上保持为一体的东西，是共同思想的无形纽带维系着它。

[38]

在现代语境中，我们把这个问题称为“碎片化的道德”。

最后一个反对不受约束的虚拟自由的理由是，虚拟现实的硬件和软件制造商不应从这类怪异行为中获利，这对所有数字技术都会产生更广泛的影响。这种观点强有力地表示，法律应禁止技术公司创造这样的技术，或要求它们编写代码，以使某些虚拟体验无法发生。换句话说，制造商应该被赋予选择其虚拟现实系统功能的自由裁量权——如果这意味着助长淫秽，那么该公司就会受到道德谴责。第二种方法有两个困难——它不能解决“道德碎片化”的问题，而且将人类自由的重要问题完全委托给了私人公司。将公共道德问题归结为企业战略问题是明智的吗？退一步说，我们的自由是否应该由科技公司的管理人员、律师和工程师的品位来决定，这本身就是值得怀疑的。面对一个只允许对某特定种族实施虚拟暴力的平台，或者是只允许异性恋而拒绝同性恋的数字平台，我们会作何感想？或者再发散下思维，若只是因为制造商反对工厂化养殖，一辆无人驾驶汽车就拒绝带乘客去快餐店，怎么办？若因为制造商是虔诚的基督徒，多功能手术机器人就拒绝做合法堕胎手术，又该如何？

诚然，技术将带来新的功能可供性，但这也意味着不道德行为和偏常行为有了我们想象不到的新机会。有些人会为这一前景欢欣鼓舞，也有人会因此不寒而栗。只要没有伤害到别人，我们就能为所欲为吗？决定这些问题的不应只有科技公司。

数字自由

先别急着往下推进，让我们现在回顾一下目前这两章的含意。我认为，我们需要的是一个新的概念集合，它们可用来解释通向自由的未来的不同途径。我在这里列出了一个适中的选择。看看哪一种最吸引你。

数字自由意志主义所代表的是一种信念，它认为未来的自由意味着不受技术影响的自由。每一行施加权力的代码都是违背自由的。自由始于技术的终结。这一学说支持缩减所有形式的数字力量，无论其本质或起源如何。任何人都不应该被迫在其他手段可以奏效的地方使用数字系统。如果我不想在家里安装“智能”电器，那么我就不应该安装它们。

数字自由主义是一种更为微妙的信念，它认为技术应该被设计来确保所有人享有最大可能的个人自由。这就是“明智的限制”路径。它的作用在于要求代码在善的不同概念之间尽可能保持中立。它不应该积极地倡导一种生活方式胜过倡导另一种生活方式，而应该给个人最大的自由空间来决定他们的道路，也许是通过对自己拥有的设备进行个性化定制。

数字邦联主义的理念是，维护自由的最佳方式是确保人们可以根据自己喜欢的代码在不同的系统之间移动。例如，如果我认为一个发言平台限制太多，我就能转向另一个。数字邦联主义要求，对于任何重要的自由，如通信、新闻收集、搜索和运输，都必须有多个可用的数字系统来行使它。而且，必须要能在这些系统之间移动而不产生负面后果。

[39]

在实践中，私人或国家垄断任何特定平台或技术，都可能对数字邦联主义造成致命影响（第十八章）。

相比之下，数字家长主义和数字道德主义认为，技术应该分别被设计来保护人们免受自身行为的有害影响，让人们远离不道德的生活。它们能做到什么程度则是一个品位问题。如果冰箱只是提醒你多吃一块馅饼的健康后果，那么它对你的限制将小于在你把它消化完之前阻止你吃更多馅饼的冰箱。一个限制极端淫秽内容的虚拟现实系统将比一个只允许用户体验有益健康的活动，如去虚拟教堂或参加虚拟讲座的虚拟现实系统要宽松得多。

最后，数字共和主义认为，任何人都不应受制于控制数字技术者的专断权力。至少，这意味着必须有人协助我们理解，控制我们生活的技术是如何实际工作的，它们所包含的价值为何，是谁设计和创造了它们，它们服务于何种目的。真正的数字共和主义则更为激进，不仅要求我们理解对我们施加权力的数字系统，而且要求我们能够参与塑造它们的实际工作。依靠科技公司的善心和智慧来为我们的自由做出重要决定是不够的。这种观点认为，只要他们可以随意改变规则，让技术为其自身利益而不是我们的利益工作，我们就认为自己一定是不自由的。实际上，即使在技术方面，这也不能算是新说。正如道格拉斯·洛西科夫（Douglas Rushkoff）所解释的，在个人电脑发展的早期，“操作电脑和为电脑编程没有什么区别”。电脑只是“我们写自己的软件的白板”。

[40]

是人在控制技术，而不是反过来。这并不是说数字共和主义意味着每个人都应该接受再培训，成为软件工程师。但这是一种激进主义。它要求公民培养让国家和科技公司承担责任所需要的公民美德：在可能的情况下去理解技术，同时还要保持警惕、谨慎、好奇、坚持、自信和公益精神。这是为了确保我们不会受制于我们无法理解、无法选择的规则，而这些规则却可以随时改变。数字共和主义者的口号可以说是要求透明、责任和参与。“去编程吧，否则就要被程序编进去了！”

[41]

自由和民主

前两个章节始终笼罩着一个隐而不彰的理念：自由和民主之间有着重要的联系。对自由主义者来说，这种联系的性质很简单：只有在民主国家，人民才能确保他们的自由不被践踏，并能参与制定“使人自由的明智的限制”。对于具有罗马传统的共和党人来说，这种联系则更为紧密。他们认为，就其对自由的危害而言，由民主程序施加的限制要小于由私人机构施加的同样限制，因为它是通过民主来决定的。正如卢梭所言：“人类由于社会契约而丧失的，乃是他的天然的自由……而他所获得的，乃是社会的自由……”

[†]

[42]

结合自由派和共和党人的路径，可以清楚地看到，民主问责制将变得比以往任何时候都重要。它将是我们对抗日益强大的国家和私人公司并自我保护时不可或缺的武器。我在第九章中说过，数字生活世界将充斥着权力和政治。如果我们关心自由，那么公民问责的能力也必须相应提高。

因此，让我们将目光转向民主。

[*]

开明人士（liberal）指的是思想自由、开通的人，其反义词为保守人士（conservative）.自由论者（libertarian）指的是认为人应当自由地行事、思考，不应该受到任何政府约束的人。——译注

[†]

此处译文参考了《社会契约论》中译本（何兆武译，商务印书馆，2003年）。——译注